{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIC: Introduction to Visual Computing - 2021/22\n",
    "## Assignment 2\n",
    "\n",
    "**Instructor:** Maria Vakalopoulou\n",
    "\n",
    "**T.A.:** Joseph Boyd\n",
    "\n",
    "**Due Date:** March 1, 2022\n",
    "\n",
    "This is VIC Assignment 2. This time you are to implement a system that outputs object detection bounding boxes of cars in a dashcam videos. You are expected to submit your prediction to a Kaggle challenge at the following link, where you will also find the dataset and further instructions:\n",
    "\n",
    "https://www.kaggle.com/t/1df65691991d413ab190f6cc4d31b968\n",
    "\n",
    "You have a set of frames available for training in the `train/` directory, and their bounding boxes in `train.csv`, having format:\n",
    "\n",
    "```x, y, width, height```\n",
    "\n",
    "Your task is to produce bounding boxes for each frame in the `test/` directory.  **N.B.** Because of limitations of in-class Kaggle, your final submission file will be of a slightly different format to `train.csv`.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated with respect to the Sørensen–Dice coefficient,\n",
    "\n",
    "$$DSC = \\frac{2|X \\cap Y|}{|X| + |Y|},$$\n",
    "\n",
    "the intersection of the prediction X and the ground truth solution Y over the sum of their. The minimum is 0 (no intersection), and the maximum is 1 (perfect overlap). The mean DSC over all test images is your final score. **N.B.** that although the challenge is posed as an object detection problem, it is evaluated as a segmentation problem i.e. X and Y will be binary masks (see below). This is due to limitations of Kaggle as used in-class mode.\n",
    "\n",
    "An unspecified 50% split of the test data contributes to a \"public leaderboard\", with the remaining data contributing to an \"private leaderboard\", which is not visible until the end of the competition. This is to prevent overfitting to the test data.\n",
    "\n",
    "## Submitting to Kaggle\n",
    "\n",
    "Submissions to the Kaggle challenge can be made in the form of a .csv file (see sample_submission.csv), consisting of two columns:\n",
    "```\n",
    "Id,Predicted\n",
    "test/001.jpg,192425 100 193705 100 ...\n",
    "test/002.jpg,192425 100 193705 100 ...\n",
    "test/003.jpg,192425 100 193705 100 ...\n",
    "...\n",
    "```\n",
    "`Id` - the image id (must be )\n",
    "\n",
    "`Predicted` - The [run length encoding](https://en.wikipedia.org/wiki/Run-length_encoding) of the binary mask resulting from your concatenated bounding boxes. It is recommended to use the supplied function `run_length_encoding` to automate this. An example is given in the .ipynb file. **N.B.** If you change the size of the images during your pipeline, be sure to resize your final bounding boxes to  (1280x720).\n",
    "\n",
    "## Grading\n",
    "\n",
    "Your work will be evaluated according to the following:\n",
    "\n",
    "- Solution design (40%): algorithmic complexity, technical innovation, performance. Simple ideas can achieve full marks if they are well-argued and perform well.\n",
    "\n",
    "- Implementation (40%): code quality, efficiency, clarity of documentation (code should be well commented). You should submit all code required to train/test your pipeline in a `.ipynb` notebook or a set of `.py` file(s).\n",
    "\n",
    "- Report (~1 page) (20%): Description of pipeline and justification of design choices, results and failure cases. In general, we want to know why you did one thing and not another.\n",
    "\n",
    "**PLUS** the best 5 will receive +1 for the grade of the assignment.\n",
    "\n",
    "**N.B.** This is an individual assignment. All students are expected to make at least one Kaggle submission and submit their own project code and report.\n",
    "\n",
    "You should send your assignment by mail to maria.vakalopoulou@centralesupelec.fr, the name of the subject of the mail should be: VIC_Assignement2_name.\n",
    "\n",
    "## FAQ\n",
    "\n",
    "**Q:** Can I use external datasets?\n",
    "\n",
    "**A:** Although we have provided extra training data, we are relaxing the constraint on external datasets. So, yes, you can.\n",
    "\n",
    "**Q:** Must I code algorithms from scratch?\n",
    "\n",
    "**A:** You will be graded on the design/implementation of your solution pipeline, which normally will comprise multiple algorithms (e.g. filters, features, machine learning). You are not required to code these individual code algorithms from scratch as has been done in the labs or previous assignment.\n",
    "\n",
    "**Q:** Can my pipeline take ages to run?\n",
    "\n",
    "**A:** It is acceptable if your training and/or testing takes some hours to run. However, in this case it should be shown that this is fully warranted.\n",
    "\n",
    "**Q:** Can I use deep learning?\n",
    "\n",
    "**A:** You are quite free in the design of your solution pipeline, however, **NO DEEP LEARNING APPROACHES ARE ALLOWED**. You should classic methods to complete this assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>bounding_boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/001.jpg</td>\n",
       "      <td>0 225 214 317 0 172 345 254 285 240 155 131 70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/002.jpg</td>\n",
       "      <td>0 254 190 293 0 169 338 271 276 238 160 137 70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/003.jpg</td>\n",
       "      <td>0 306 59 241 0 155 306 318 235 233 191 149 713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/004.jpg</td>\n",
       "      <td>0 143 239 298 164 223 240 172 721 293 94 76 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/005.jpg</td>\n",
       "      <td>0 217 137 270 55 209 323 208 731 296 99 79 573...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        frame_id                                     bounding_boxes\n",
       "0  train/001.jpg  0 225 214 317 0 172 345 254 285 240 155 131 70...\n",
       "1  train/002.jpg  0 254 190 293 0 169 338 271 276 238 160 137 70...\n",
       "2  train/003.jpg  0 306 59 241 0 155 306 318 235 233 191 149 713...\n",
       "3  train/004.jpg  0 143 239 298 164 223 240 172 721 293 94 76 57...\n",
       "4  train/005.jpg  0 217 137 270 55 209 323 208 731 296 99 79 573..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv('./train.csv')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[68, 70, 49],\n",
       "        [72, 73, 55],\n",
       "        [64, 65, 49],\n",
       "        ...,\n",
       "        [21, 42, 23],\n",
       "        [27, 48, 29],\n",
       "        [32, 53, 34]],\n",
       "\n",
       "       [[61, 63, 42],\n",
       "        [73, 75, 54],\n",
       "        [53, 54, 38],\n",
       "        ...,\n",
       "        [31, 52, 33],\n",
       "        [40, 61, 42],\n",
       "        [43, 64, 45]],\n",
       "\n",
       "       [[69, 71, 49],\n",
       "        [51, 53, 32],\n",
       "        [33, 34, 16],\n",
       "        ...,\n",
       "        [45, 66, 47],\n",
       "        [46, 67, 48],\n",
       "        [45, 66, 47]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[26, 36, 45],\n",
       "        [25, 35, 44],\n",
       "        [25, 35, 44],\n",
       "        ...,\n",
       "        [47, 62, 67],\n",
       "        [47, 62, 67],\n",
       "        [47, 62, 67]],\n",
       "\n",
       "       [[26, 36, 45],\n",
       "        [26, 36, 45],\n",
       "        [26, 36, 45],\n",
       "        ...,\n",
       "        [48, 63, 68],\n",
       "        [47, 62, 67],\n",
       "        [47, 62, 67]],\n",
       "\n",
       "       [[26, 36, 45],\n",
       "        [26, 36, 45],\n",
       "        [26, 36, 45],\n",
       "        ...,\n",
       "        [48, 63, 68],\n",
       "        [47, 62, 67],\n",
       "        [46, 61, 66]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, W = 720, 1280\n",
    "N = len(df_ground_truth)\n",
    "\n",
    "\n",
    "def read_frame(df_annotation, frame):\n",
    "    \"\"\"Read frames and create integer frame_id-s\"\"\"\n",
    "    file_path = df_annotation[df_annotation.index == frame]['frame_id'].values[0]\n",
    "    return imread(file_path)\n",
    "\n",
    "read_frame(df_ground_truth, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "H, W = 720, 1280\n",
    "N = len(df_ground_truth)\n",
    "\n",
    "\n",
    "def read_frame(df_annotation, frame):\n",
    "    \"\"\"Read frames and create integer frame_id-s\"\"\"\n",
    "    file_path = df_annotation[df_annotation.index == frame]['frame_id'].values[0]\n",
    "    return imread(file_path)\n",
    "\n",
    "def annotations_for_frame(df_annotation, frame):\n",
    "    assert frame in df_annotation.index\n",
    "    bbs = df_annotation[df_annotation.index == frame].bounding_boxes.values[0]\n",
    "\n",
    "    if pd.isna(bbs): # some frames contain no vehicles\n",
    "        return []\n",
    "\n",
    "    bbs = list(map(lambda x : int(x), bbs.split(' ')))\n",
    "    return np.array_split(bbs, len(bbs) / 4)\n",
    "\n",
    "def show_annotation(df_annotation, frame):\n",
    "    img = read_frame(df_annotation, frame)\n",
    "    bbs = annotations_for_frame(df_annotation, frame)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    for x, y, dx, dy in bbs:\n",
    "\n",
    "        rect = patches.Rectangle((x, y), dx, dy, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('Annotations for frame {}.'.format(frame))\n",
    "\n",
    "def bounding_boxes_to_mask(bounding_boxes, H, W):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts set of bounding boxes to a binary mask\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros((H, W))\n",
    "    for x, y, dx, dy in bounding_boxes:\n",
    "        mask[y:y+dy, x:x+dx] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def run_length_encoding(mask):\n",
    "\n",
    "    \"\"\"\n",
    "    Produces run length encoding for a given binary mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # find mask non-zeros in flattened representation\n",
    "    non_zeros = np.nonzero(mask.flatten())[0]\n",
    "    padded = np.pad(non_zeros, pad_width=1, mode='edge')\n",
    "    \n",
    "    # find start and end points of non-zeros runs\n",
    "    limits = (padded[1:] - padded[:-1]) != 1\n",
    "    starts = non_zeros[limits[:-1]]\n",
    "    ends = non_zeros[limits[1:]]\n",
    "    lengths = ends - starts + 1\n",
    "\n",
    "    return ' '.join(['%d %d' % (s, l) for s, l in zip(starts, lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6138d28cf4f491a9f4b2bc1010e805e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_id', max=2226, min=1), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_display(frame_id)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def f_display(frame_id):\n",
    "    show_annotation(df_ground_truth, frame_id)\n",
    "\n",
    "interact(f_display, frame_id=widgets.IntSlider(min=1, max=N, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Kaggle submission file\n",
    "\n",
    "Suppose we have a set of bounding boxes of format `x, y, width, height`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = [[0, 0, 5, 5], [5, 5, 5, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's say they are the same for all test images (yours won't be). Then, we can create a Kaggle submission file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir('./test/'))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for file_name in test_files:\n",
    "    \n",
    "    rle = run_length_encoding(bounding_boxes_to_mask(bounding_boxes, H, W))\n",
    "    rows.append([file_name, rle])\n",
    "\n",
    "df_prediction = pd.DataFrame(columns=['Id', 'Predicted'], data=rows).set_index('Id')\n",
    "df_prediction.to_csv('sample_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
